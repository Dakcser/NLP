Feature selection is an important task in data mining and machine learning to reduce the dimensionality of the data and increase the performance of an algorithm, such as a classification algorithm. However, feature selection is a challenging task due mainly to the large search space. A variety of methods have been applied to solve feature selection problems, where evolutionary computation (EC) techniques have recently gained much attention and shown some success. However, there are no comprehensive guidelines on the strengths and weaknesses of alternative approaches. This leads to a disjointed and fragmented field with ultimately lost opportunities for improving performance and successful applications. This paper presents a comprehensive survey of the state-of-the-art work on EC for feature selection, which identifies the contributions of these different algorithms. In addition, current issues and challenges are also discussed to identify promising areas for future research.

In data mining and machine learning, real-world problems often involve a large number of features. However, not all features are essential since many of them are redundant or even irrelevant, which may reduce the performance of an algorithm, e.g., a classification algorithm. Feature selection aims to solve this problem by selecting only a small subset of relevant features from the original large set of features. By removing irrelevant and redundant features, feature selection can reduce the dimensionality of the data, speed up the learning process, simplify the learned model, and/or increase the performance [1], [2]. Feature construction (or feature extraction) [3]–[4][5], which can also reduce the dimensionality, is closely related to feature selection. The major difference is that feature selection selects a subset of original features while feature construction creates novel features from the original features. This paper focuses mainly on feature selection.
Feature selection is a difficult task due mainly to a large search space, where the total number of possible solutions is 2n for a dataset with n features [1], [2]. The task is becoming more challenging as n is increasing in many areas with the advances in the data collection techniques and the increased complexity of those problems. An exhaustive search for the best feature subset of a given dataset is practically impossible in most situations. A variety of search techniques have been applied to feature selection, such as complete search, greedy search, heuristic search, and random search [1], [6]–[7][8][9]. However, most existing feature selection methods still suffer from stagnation in local optima and/or high computational cost [10], [11]. Therefore, an efficient global search technique is needed to better solve feature selection problems. Evolutionary computation (EC) techniques have recently received much attention from the feature selection community as they are well-known for their global search ability/potential. However, there are no comprehensive guidelines on the strengths and weaknesses of alternative approaches along with their most suitable application areas. This leads to progress in the field being disjointed, shared best practice becoming fragmented and, ultimately, opportunities for improving performance and successful applications being missed. This paper presents a comprehensive survey of the literature on EC for feature selection with the goal of providing interested researchers with the state-of-the-art research.
Feature selection has been used to improve the quality of the feature set in many machine learning tasks, such as classification, clustering, regression, and time series prediction [1]. This paper focuses mainly on feature selection for classification since there is much more work on feature selection for classification than for other tasks [1]. Recent reviews on feature selection can be seen in [7], [8], [12], and [13], which focus mainly on non-EC-based methods. De la Iglesia [14] presented a summary of works using EC for feature selection in classification, which is suitable for a non-EC audience since it focuses on basic EC concepts and genetic algorithms (GAs) for feature selection. De la Iglesia [14] reviewed only 14 papers published since 2010 and in total 21 papers since 2007. No papers published in the most recent two years were reviewed [14], but there have been over 500 papers published in the last five years. Research on EC for feature selection started around 1990, but it has become popular since 2007, when the number of features in many areas became relatively large. Fig. 1 shows the number of papers on the two most popular EC methods in feature selection, i.e., GAs and particle swarm optimization (PSO), which shows that the number of papers, especially on PSO, has significantly increased since 2007. (Note that the numbers were obtained from Google Scholar on September 2015. These numbers might not be complete, but they show the general trend of the field. The papers used to form this survey were collected from all the major databases, such as Web of Science, Scopus, and Google Scholar.) We aim to provide a comprehensive survey of the state-of-the-art work and a discussion of the open issues and challenges for future work. We expect this survey to attract attention from researchers working on different EC paradigms to further investigate effective and efficient approaches to addressing new challenges in feature selection. This paper is also expected to encourage researchers from the machine learning community, especially classification, to pay much attention to the use of EC techniques to address feature selection problems.
The remainder of this paper is organized as follows. Section II describes the background of feature selection. Section III reviews typical EC algorithms for feature selection. Section IV discusses different measures used in EC for feature selection. Section V presents the applications of EC-based feature selection approaches. Section VI discusses current issues and challenges, and the conclusion is given in Section VII.

This paper provided a comprehensive survey of EC techniques in solving feature selection problems, which covered all the commonly used EC algorithms and focused on the key factors, such as representation, search mechanisms, and the performance measures as well as the applications. Important issues and challenges were also discussed.
This survey shows that a variety of EC algorithms have recently attracted much attention to address feature selection tasks. A popular approach in GAs, GP, and PSO is to improve the representation to simultaneously select features and optimize the classifiers, e.g., SVMs. Different algorithms have their own characteristics, such as GAs are able to preserve a small set of features during the evolutionary process because of the nature of genetic operators, PSO is relatively computationally cheap because of its simple updating mechanisms, ACO can gradually add features because of the graph representation, and GP can implicitly perform feature selection through feature construction. Therefore, these EC techniques or their combinations can be used with different measures to solve different types of feature selection problems. This needs further investigation in the future. Furthermore, all the major EC algorithms, e.g., GAs, GP, and PSO, have been used to address feature selection tasks with thousands of features, but they suffer from the problem of high computational cost. As a result, when they are applied to large-scale feature selection tasks, the current target datasets usually have a small number of instances.
Although EC techniques for feature selection have achieved some success, they still face challenges and their potential has not been fully investigated. Scalability is one of the most important issues since both the number of features and the number of instances are increasing in many real-world tasks. This is not only a challenging task in EC, but also in the machine learning, statistics, and biology communities. The recent advances in EC for large-scale global optimization motivate further studies on EC for large-scale feature selection, but it is challenging to develop promising approaches, where novel search mechanisms and representation schemes are needed in both single objective and multi-objective feature selection. To improve their effectiveness and efficiency, it is necessary to design a cheap evaluation measure according to the specific representation and the search mechanism of a particular EC technique. The proposal of novel approaches may involve methods or measures from different areas, which encourages research across multiple disciplines. A comprehensive comparison between EC and non-EC approaches on a large number of benchmark datasets/problems to test their advantages and disadvantages can help develop novel effective approaches to different kinds of problems. In addition, combining feature selection with feature construction can potentially improve the classification performance, whereas combining feature selection with instance selection can potentially improve the efficiency.