With a massive influx of multimodality data, the role of data analytics in health informatics has grown rapidly in the last decade. This has also prompted increasing interests in the generation of analytical, data driven models based on machine learning in health informatics. Deep learning, a technique with its foundation in artificial neural networks, is emerging in recent years as a powerful tool for machine learning, promising to reshape the future of artificial intelligence. Rapid improvements in computational power, fast data storage, and parallelization have also contributed to the rapid uptake of the technology in addition to its predictive power and ability to generate automatically optimized high-level features and semantic interpretation from the input data. This article presents a comprehensive up-to-date review of research employing deep learning in health informatics, providing a critical analysis of the relative merit, and potential pitfalls of the technique as well as its future outlook. The paper mainly focuses on key applications of deep learning in the fields of translational bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health.

Deep learning has in recent years set an exciting new trend in machine learning. The theoretical foundations of deep learning are well rooted in the classical neural network (NN) literature. But different to more traditional use of NNs, deep learning accounts for the use of many hidden neurons and layers—typically more than two—as an architectural advantage combined with new training paradigms. While resorting to many neurons allows an extensive coverage of the raw data at hand, the layer-by-layer pipeline of nonlinear combination of their outputs generates a lower dimensional projection of the input space. Every lower-dimensional projection corresponds to a higher perceptual level. Provided that the network is optimally weighted, it results in an effective high-level abstraction of the raw data or images. This high level of abstraction renders an automatic feature set, which otherwise would have required hand-crafted or bespoke features.
In domains such as health informatics, the generation of this automatic feature set without human intervention has many advantages. For instance, in medical imaging, it can generate features that are more sophisticated and difficult to elaborate in descriptive means. Implicit features could determine fibroids and polyps  [1], and characterize irregularities in tissue morphology such as tumors  [2]. In translational bioinformatics, such features may also determine nucleotide sequences that could bind a DNA or RNA strand to a protein [3] . Fig. 1 outlines a rapid surge of interest in deep learning in recent years in terms of the number of papers published in sub-fields in health informatics including bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health.
Among various methodological variants of deep learning, several architectures stand out in popularity. Fig. 2 depicts the number of publications by deep learning method since 2010. In particular, Convolutional Neural Networks (CNNs) have had the greatest impact within the field of health informatics. Its architecture can be defined as an interleaved set of feed-forward layers implementing convolutional filters followed by reduction, rectification or pooling layers. Each layer in the network originates a high-level abstract feature. This biologically-inspired architecture resembles the procedure in which the visual cortex assimilates visual information in the form of receptive fields. Other plausible architectures for deep learning include those grounded in compositions of restricted Boltzmann machines (RBMs) such as deep belief networks (DBNs), stacked Autoencoders functioning as deep Autoencoders, extending artificial NNs with many layers as deep neural networks (DNNs), or with directed cycles as recurrent neural networks (RNNs). Latest advances in Graphics Processing Units (GPUs) have also had a significant impact on the practical uptake and acceleration of deep learning. In fact, many of the theoretical ideas behind deep learning were proposed during the pre-GPU era, although they have started to gain prominence in the last few years. Deep learning architectures such as CNNs can be highly parallelized by transferring most common algebraic operations with dense matrices such as matrix products and convolutions to the GPU.
Thus far, a plethora of experimental works have implemented deep learning models for heath informatics, reaching similar performance or in many cases exceeding that of alternative techniques. Nevertheless, the application of deep learning to health informatics raises a number of challenges that need to be resolved. For example, training a deep architecture requires an extensive amount of labeled data, which in the healthcare domain can be difficult to achieve. In addition, deep learning requires extensive computational resources, without which training could become excessively time-consuming. Attaining an optimal definition of the network's free parameters can become a particularly laborious task to solve. Eventually, deep learning models can be affected by convergence issues as well as overfitting, hence supplementary learning strategies are required to address these problems  [4].
In the following sections of this review, we examine recent health informatics studies that employ deep learning to discuss its relative strength and potential pitfalls. Furthermore, their schemas and operational frameworks are described in detail to elucidate their practical implementations, as well as expected performance.
Perceptron is a bio-inspired algorithm for binary classification and it is one of the earliest NNs proposed  [19]. It mathematically formalizes how a biological neuron works. It has been realized that the brain processes information through billions of these interconnected neurons. Each neuron is stimulated by the injection of currents from the interconnected neurons and an action potential is generated when the voltage exceeds a limit. These action potentials allow neurons to excite or inhibit other neurons, and through these networked neural activities, the biological network can encode, process, and transmit information. Biological NNs have the capacity to modify themselves, create new neural connections, and learn according to the stimulation characteristics. Perceptrons, which consist of an input layer directly connected to an output node, emulate this biochemical process through an activation function (also referred to as a transfer function) and a few weights. Specifically, it can learn to classify linearly separable patterns by adjusting these weights accordingly.

Deep learning has gained a central position in recent years in machine learning and pattern recognition. In this paper, we have outlined how deep learning has enabled the development of more data-driven solutions in health informatics by allowing automatic generation of features that reduce the amount of human intervention in this process. This is advantageous for many problems in health informatics and has eventually supported a great leap forward for unstructured data such as those arising from medical imaging, medical informatics, and bioinformatics. Until now, most applications of deep learning to health informatics have involved processing health data as an unstructured source. Nonetheless, a significant amount of information is equally encoded in structured data such as EHRs, which provide a detailed picture of the patient's history, pathology, treatment, diagnosis, outcome, and the like. In the case of medical imaging, the cytological notes of a tumor diagnosis may include compelling information like its stage and spread. This information is beneficial to acquire a holistic view of a patient condition or disease and then be able to improve the quality of the obtained inference. In fact, robust inference through deep learning combined with artificial intelligence could ameliorate the reliability of clinical decision support systems. However, several technical challenges remain to be solved. Patient and clinical data is costly to obtain and healthy control individuals represent a large fraction of a standard health dataset. Deep learning algorithms have mostly been employed in applications where the datasets were balanced, or, as a work-around, in which synthetic data was added to achieve equity. The later solution entails a further issue as regards the reliance of the fabricated biological data samples. Therefore, methodological aspects of NNs need to be revisited in this regard. Another concern is that deep learning predominantly depends on large amounts of training data. Such requirements make more critical the classical entry barriers of machine learning, i.e., data availability and privacy. Consequently, advances in the development of seamless and fast equipment for health monitoring and diagnoses will play a prominent role in future research. Reference to the issue of computational power, we envisage that for the years to come, further ad hoc hardware platforms for neural networks and deep learning processing will be announced and made commercially available. It is worth noting that the rise of deep learning has been mightily supported by major IT companies (e.g., Google, Facebook, and Baidu) which hold a large extent of patents in the field and core businesses are substantially supported by data gathering, enormous storehouses and processing machines. Many researchers have been encouraged to apply deep learning to any data-mining and pattern recognition problem related to health informatics in light of the wide availability of free packages to support this research. Looking at it from the bright side, it has fostered an interesting trend and boosted the expectations of what machine learning could achieve on its own. Nevertheless, we should not consider deep learning as a silver bullet for every single challenge set by health informatics. In practice, it is still questionable whether the large amount of training data and computational resources needed to run deep learning at full performance is worthwhile, considering other fast learning algorithms that may produce close performance with fewer resources, less parameterization, tuning, and higher interpretability. Therefore, we conclude that deep learning has provided a positive revival of NNs and connectionism from the genuine integration of the latest advances in parallel processing enabled by coprocessors. Nevertheless, a sustained concentration of health informatics research exclusively around deep learning could slow down the development of new machine learning algorithms with a more conscious use of computational resources and interpretability.